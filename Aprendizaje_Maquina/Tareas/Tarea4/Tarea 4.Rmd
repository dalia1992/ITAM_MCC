---
title: "Tarea 4: regresión logística"
output: html_document
---

En esta tarea construiremos varios modelos de regresión logística
y compararemos sus resultados.

### Preparación

Puedes usar el siguiente código, o tus implementaciones propias:

```{r}
source("tarea_4_codigo.R")
```

Revisa las funciones que están ahí. Son las que usamos en clase.

Usaremos los datos de sobrevivientes del hundimiento del Titanic,
obtenidos de [este concurso de Kaggle](https://www.kaggle.com/c/titanic)

```{r}
library(tidyverse)
datos_titanic <- read_csv("./tarea_4_datos/train.csv")
```

En este caso, queremos predecir la variable *Survived* en términos del resto.
Para simiplificar el ejericicio, 

- solo usaremos alguna de las variables,
- ignoramos datos faltantes en la variable edad

```{r}
datos_titanic <- datos_titanic %>% select(Survived, Pclass, Age, Sex, Embarked) %>%
  filter(!is.na(Age), !is.na(Embarked))
summary(datos_titanic)
head(datos_titanic)
```

La descripción de las variables es:

survival	Survival	0 = No, 1 = Yes
pclass	Ticket class	1 = 1st, 2 = 2nd, 3 = 3rd
sex	Sex	
Age	Age in years	
embarked	Port of Embarkation	C = Cherbourg, Q = Queenstown, S = Southampton

Convertimos las variables categóricas a numerícas creando indicadoras, como
sigue:

```{r}
datos <- datos_titanic %>% 
  mutate(female = as.numeric(Sex == "female"),
         southampton = as.numeric(Embarked == "S"),
         cherbourg = as.numeric(Embarked == "C")) %>%
  select(-Embarked, -Sex)
datos
```

Consierando cómo se ven estos datos, podemos usar una normalización simple
(puedes también hacerlo como lo hicimos en clase), de forma que todas las variables
estén aproximadamente en el rango 0 - 1 :

```{r}
datos$age_n <- datos$Age / 60
datos$pclass_n <-(datos$Pclass - 1) / 3
datos_trans <- datos %>% select(Survived, pclass_n, age_n, female, southampton, cherbourg)
datos_trans
```



Y finalmente, separa en entrenamiento y prueba de esta forma (como estamos
normalizando con cantidades fijas, no tenemos que normalizar por separado):

```{r}
set.seed(2850)
datos_trans <- datos_trans %>% 
  mutate(u = runif(nrow(datos_trans))) 
entrena <- datos_trans %>% filter(u <= 0.7) %>% select(-u)
prueba <- datos_trans %>% filter(u > 0.7) %>% select(-u)
```

```{r}
nrow(entrena)
nrow(prueba)
x_ent <- as.matrix(entrena %>% select(-Survived))
x_pr <- as.matrix(prueba %>% select(-Survived))
y_ent <- entrena$Survived
y_pr <- prueba$Survived
```


### Ejercicio A

1. Ajusta un modelo usando solo una variable (por ejemplo, el indicador si 
abordó en cherbourg). Ajusta el tamaño de paso y checa convergencia

```{r}
x_ent_1 <- x_ent[ , "cherbourg", drop = FALSE] # drop=false es para no convertir en vector
devianza_ent <- devianza_calc(x_ent_1, y_ent)
grad_ent <- grad_calc(x_ent_1, y_ent)
## termina esta línea para descenso en gradiente
n <- 10000
z <- descenso(n = n, z_0 = rep(0, 2), eta = 0.0001, h_deriv = grad_ent)
```

2. Calcula ahora la devianza de prueba de este modelo

```{r}
x_pr_1 <-  x_pr[ , "cherbourg", drop = FALSE]
devianza_pr <- devianza_calc(x_pr_1, y_pr)
# termina esta línea
devianza_pr(z[n,])
```
La devianza de prueba es 266.99. 

3. Para este modelo simple, calcula la probabilidad estimada por el modelo
de sobrevivir 
para una persona que embarcó en cherbourg y una que no:

```{r}
# Rellena:
# probabilidad sobrevivir si no embarcó en Cherbourg
h(z[n,]%*%c(1,0))
# probabilidad si embarcó  en Cherbourg
h(z[n,]%*%c(1,1))
```


### Ejercicio B

Ahora utiliza todas las variables, y repite el ejercicio anterior:

1. Ajusta un modelo usando solo una variable (por ejemplo, el indicador si 
abordó en cherbourg). Ajusta el tamaño de paso y checa convergencia

```{r}
devianza_ent <- devianza_calc(x_ent, y_ent)
grad_ent     <- grad_calc(x_ent, y_ent)
## termina esta línea
z <- descenso(n = n, z_0 = rep(0, 6),eta = 0.0001, h_deriv = grad_ent)
devianza_ent(z[n,])
```

2. Calcula ahora la devianza de prueba de este modelo

```{r}
devianza_pr <- devianza_calc(x_pr, y_pr)
devianza_pr(z[n,])
```
La devianza de prueba es 216.5 .

3. Calcula la probabidad estimada de que un hombre con boleto de 3a clase, de 60 años,
que abordó en southampton sobreviva. Repite para una mujer con boleto de 1a clase, de 60
años, que abordó en southampton
```{r}
# Hombre de 60 años en tercera clase southhampton
h(z[n,]%*%c(1,2/3,1,0, 1,0))

# Mujer de 60 años en primera clase southhampton
h(z[n,]%*%c(1,0,1,1, 1,0))

```

4. Grafica las probabilidades estimadas para alguien que subió en Southampton,
para todos los rangos de edad, hombres y mujeres, de las tres clases posibles. Puedes
empezar con el siguiente código:

```{r}
# vamos a calcular proabilidades para estos datos
dat_calc <- expand.grid(list ( pclass_n = unique(x_ent[,"pclass_n"]),
                               age_n = unique(x_ent[, "age_n"]),
                               female = c(0,1),
                               southampton = 1,
                               cherbourg = 0))
mat_calc <- as.matrix(dat_calc)
## rellena aquí las betas que obtuviste
beta <-z[n,]
# calcula las probabilidades (puedes usar la fucnión p_beta, por ejemplo)
dat_calc$p_surv <- as.vector(h(cbind(1,mat_calc)%*%beta))
ggplot(dat_calc, aes(x = age_n, y = p_surv, colour= factor(pclass_n), group=factor(pclass_n))) +
  facet_wrap(~female) + geom_line() + ylim(c(0, 1)) +
  labs(title = "Probabilidades superviviencia (Pasajeros de Southampton)")
```

¿Cuáles son las probabilidades más altas? ¿Cuáles son las más bajas?
```{r}
# Probabilidades más altas
  dat_calc %>% 
  dplyr::arrange(desc(p_surv)) %>% 
  glimpse

# Probabilidades más bajas
  dat_calc %>% 
  dplyr::arrange(p_surv) %>% 
  glimpse
```

5. ¿Cuál de los dos modelos anteriores (una sola variable, todas las variables)
se desempeña mejor? ¿Por qué? 

El segundo, por que la devianza de prueba es menor.


6. Calcula el error de clasificación de prueba 
```{r}
mean(abs(prueba$Survived - round(h(cbind(1,x_pr)%*%beta))))
```


### Ejercicio C

Ahora supondremos que tenemos algunas variables adicionales para incluir en el modelo.
En este ejercicio veremos qué sucede si estas variables **no** pueden ayudarnos
a predecir (las simulamos al azar)

Dada la escala de nuestras variables, podemos simular variables con valores entre 0 y 1

```{r}
#set.seed(744546)
set.seed(201)
p_ruido <- 50 # agregamos 50 variables sin información
n_ent <- nrow(x_ent)
n_pr <- nrow(x_pr)
mat_ent <- matrix(runif(n_ent * p_ruido), n_ent, p_ruido)
mat_pr <- matrix(runif(n_pr * p_ruido), n_pr, p_ruido)
head(mat_ent)
```

1. Ajusta un modelo usando todas las variables, incluyendo
las generadas aleatoriamente:

```{r}
devianza_ent <- devianza_calc(cbind(x_ent, mat_ent), y_ent)
grad_ent <- grad_calc(cbind(x_ent, mat_ent), y_ent)
## termina esta línea
z <- descenso(n = n, z_0 = rep(0,56), eta = 0.0001, h_deriv = grad_ent)
```

2. Calcula ahora la devianza de prueba de este modelo

```{r}
devianza_pr <- devianza_calc(cbind(x_pr, mat_pr), y_pr)
devianza_pr(z[n,])
```
La deviamza de prueba es casi la misma que sin las veriables de ruido. Con las variables de ruido aumenta en 0.03 aproximadamente.

Prueba utilizando otras semillas. Contesta:

- ¿Cómo es la devianza de prueba
de el modelo con las variables ruidosas en comparación al modelo con
las seis variables originales?

Con otras semillas el error de prueba cambia aunque sigue estando cercano al modelo sin ruido.

- ¿Podría ser que la devianza de prueba fuera un poco mejor para el modelo
ruidoso?¿Por qué sí o por qué no? 
Sí en caso de que el ruido se hay distribuido de una maner adecuada, sin embargo no cambia mucho.

- ¿Cómo se compara la devianza de *entrenamiento* del modelo con 6 variables
con el modelo con todas las variables ruidosas?

```{r}
devianza_ent(z[n,])
```
La devianza de entrenamiento es menor con las variables ruidosas.

3. Haz pruebas agregando 2 o 3 variables ruidosas. ¿Qué tan grande es la diferencia
entre la evaluación de los modelos?

Repetir el modelo de cherbourg con 3 variables de ruido
```{r}
set.seed(55851)
x_ent_1 <- x_ent[ , "cherbourg", drop = FALSE] # drop=false es para no convertir en vector
x_ent_1 <- cbind(x_ent_1,runif(512), runif(512), runif(512))
devianza_ent <- devianza_calc(x_ent_1, y_ent)
grad_ent <- grad_calc(x_ent_1, y_ent)
## termina esta línea para descenso en gradiente
z <- descenso(n = n, z_0 = rep(0, 5), eta = 0.0001, h_deriv = grad_ent)
```

Devianza de prueba de este modelo

```{r}
x_pr_1 <-  x_pr[ , "cherbourg", drop = FALSE]
devianza_pr <- devianza_calc(cbind(x_pr_1, runif(200), runif(200), runif(200)), y_pr)
# termina esta línea
devianza_pr(z[n,])
```

Repetir con todas las variables y 3 variables de ruido

```{r}
x_ent <- cbind(x_ent, runif(512), runif(512), runif(512))
devianza_ent <- devianza_calc(x_ent, y_ent)
grad_ent     <- grad_calc(x_ent, y_ent)
## termina esta línea
z <- descenso(n = n, z_0 = rep(0, 9),eta = 0.0001, h_deriv = grad_ent)
devianza_ent(z[n,])
```

2. Calcula ahora la devianza de prueba de este modelo

```{r}
devianza_pr <- devianza_calc(cbind(x_pr, runif(200), runif(200), runif(200)), y_pr)
devianza_pr(z[n,])
```
La comparación entre ambos modelos sigue mostrando que es mejor utilizar más variables que sólo cherbourg y ruido