---
title: "Examen Final"
author: "Dalia Camacho y Gabriela Vargas"
date: "December 4, 2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Final {-}

* Puede realizarse individual o en parejas.

* Enviar por correo electónico documento final (no Rmd).

* Entregar **sábado 8 antes de las 20:00 hr**, después de eso se califica sobre
7 (máximo entregar domingo a las 13:00 hrs).

* Incluir código y respuestas que describan lo que se hizo.

* Dudas y artículo para pregunta 3 [aquí](https://drive.google.com/open?id=1IadZgMhrTAsll8YLLwcnBhk17UcwOdtK).

### 1. Inferencia gráfica {-}

```{r, message=FALSE}
library(tidyverse)
library(knitr)
```

Para este ejercicio utilizaremos los datos de un estudio
longitudinal de _Singer y Willet 2003_ (wages). En este estudio se visitó a
hombres en edad laboral que habitan en EUA, se visitó a cada sujeto entre 1 y 13
veces, en cada visita se registraron las siguientes mediciones:

id: identificador de sujeto  
hgc: grado de educación más alto completado  
lnw : logaritmo natural del salario  
exper: años de experiencia laboral  

El objetivo del ejercicio es estudiar la relación entre salario y experiencia
laboral por raza para aquellos sujetos cuyo año máximo de estudios completados 
es igual a 9, 10 u 11, estos son sujetos que abandonaron sus estudios durante
preparatoria. Seguiremos un enfoque no paramétrico que consiste en ajustar un 
suavizador para cada grupo de raza (blanco, hispano o negro) como se muestra 
en la siguiente gráfica.

```{r}
load("data/wages_t.RData")
```

```{r}
ggplot(wages_t, aes(x = exper, y = lnw)) +
  geom_point(alpha = 0.25, size = 2) + 
  geom_smooth(aes(group = race, color = race), method = "loess", se = FALSE) 
```

Utilizaremos una prueba de hipótesis gráfica para determinar si existe una 
diferencia significativa entre las curvas.

1. **Preparación de los datos**.  

* Selecciona los sujetos con grado de estudios completado igual a 9, 10 u 11.

Los datos ya estaban filtrados por grado de estudios completados de 9 a 11.

* Elimina las observaciones donde el logaritmo del salario (lnw) es mayor a 3.5.
```{r}
# Se eliminan las observaciones en las que el salario en escala logarìtmica
# es mayor a 3.5
wages_t <- wages_t %>% filter(lnw<=3.5)
```


* Crea una variable correspondiente a raza, un sujeto es de raza hispana si 
la variable hispanic toma el valor 1, de raza negra si la variable black
toma el valor 1 y de raza blanca si las dos anteriores son cero.

La variable raza ya está presente en la base original.


* Crea un subconjunto de la base de datos de tal manera que tengas el mismo 
número de sujetos distintos en cada grupo de raza. Nota: habrá el mismo número
de sujetos en cada grupo pero el número de observaciones puede diferir pues los
sujetos fueron visitados un número distinto de veces. 

```{r}
# Se elige una semilla
set.seed(6583)

# Se cuenta el número de individuos en cada grupo racial
Nhispanic <- unique(wages_t$id[wages_t$race=="hispanic"])
Nblack    <- unique(wages_t$id[wages_t$race=="black"])
Nwhite    <- unique(wages_t$id[wages_t$race=="white"])

# Obtenemos el número de individuos que se conservan de cada grupo racial
Nrace     <- min(length(Nhispanic), length(Nblack), length(Nwhite))

# Se obtiene la muestra con el número de individuos obtenido anteriormente
Nhispanic <- sample(Nhispanic, Nrace)
Nblack    <- sample(Nblack, Nrace)
Nwhite    <- sample(Nwhite, Nrace)

wages_t <- wages_t %>% filter(id %in% c(Nhispanic,Nblack,Nwhite))

```

2 **Prueba de hipótesis visual**  

* El escenario nulo consiste en que no hay diferencia entre las razas. Para
generar los datos nulos, la etiqueta de raza de cada sujeto se permuta, 
es decir, se reasigna la raza de cada sujeto de manera aleatoria (para todas las
mediciones de un sujeto dado se reasigna una misma raza). Genera 10 conjuntos de
datos nulos y para cada uno ajusta una curva _loess_ siguiendo la instrucción de
la gráfica de arriba. Crea una gráfica de paneles donde incluyas los 10
conjuntos nulos y los datos reales, estos últimos estarán escondidos de manera
aleatoria.

```{r}
# Cargamos la librería nullabor
library(nullabor)
```

```{r}
# Fijamos una nueva semilla 
set.seed(9293)

# Fijamos los datos reales en la posición 5 y para otros 9 casos
# permutamos el valor de raza
wages_null <- lineup(null_permute('race'), n = 10, wages_t, pos = 5)

# Graficamos los datos originales y permutados en una gráfica de paneles
ggplot(wages_null, aes(x = exper, y = lnw)) +
  geom_point(alpha = 0.25, size = 2) + 
  facet_wrap(~ .sample)+
  geom_smooth(aes(group = race, color = race), method = "loess", se = FALSE) 

```


* Realiza la siguiente pregunta a una o más personas __que no tomen la clase__:

_Las siguientes 10 gráficas muestran suavizamientos de log(salarios) por años
de experiencia laboral. Una de ellas usa datos reales y las otras 9 son datos
nulos, generados bajo el supuesto de que no existe diferencia entre los 
subgrupos. ¿Cuál es la gráfica más distinta?_

Le preguntamos a una persona y eligió correctamente la gráfica 5, aunque también dudó sobre la gráfica 8.

Reporta si las personas cuestionadas pudieron distinguir los datos.

* ¿Cuál es tu conclusión de la prueba de hipótesis visual?
La prueba de hipótesis visual puede dar buenos resultados, sin embargo siempre está presente la observación subjetiva del observador.


* ¿A cuántas personas preguntaste y cuál es el valor p de la prueba?
Le preguntamos a una persona, el valor-p de la prueba es $0.1$.



### 2. Simulación para el cálculo de tamaños de muestra

En el conteo rápido del estado de Guanajuato, se calculó el tamaño de muestra
fijando como objetivo que los intervalos del $95$% de confianza tuvieran una 
longitud máxima de 2 puntos porcentuales para todos los candidatos. En este 
ejercicio calcularás el tamaño de muestra mínimo que cumpla con el objetivo
usando 3 diseños de muestreo distintos: 1) muestreo aleatorio simple (MAS), 
2) estratificando con distrito local y 3) estratificando con distrito federal.

Utilizarás simulación y los resultados de las elecciones de gobernador 
correspondientes al 2012.

```{r}
# Cargamos la base de datos gto_2012
gto_2012 <- read.csv("data/gto_2012.csv", stringsAsFactors = FALSE)
```

En el caso de **MAS**, para cada tamaño de muestra 
$n=50,100,200,300,400,500,600,700$:

i. Simula una muestra aleatoria de tamaño $n$.

ii. Calcula el estimador de razón (correspondiente a muestreo aleatorio simple) 
para cada candidato:

$$\hat{p}=\frac{\sum_{i} Y_{i}}{\sum_i X_{i}}$$
$$\hat{p}=\frac{\sum_h \frac{N_h}{n_h} \sum_i Y_{hi}}{\sum_h \frac{N_h}{n_h} \sum_i X_{hi}}$$
donde:

* $\hat{p}$ es la estimación de la proporción de votos que recibió el candidato
en la elección.

* $Y_{i}$ es el número total de votos que recibió el candidato
en la $i$-ésima casilla.

* $X_{i}$ es el número total de votos en la $i$-ésima casilla. 

iii. Repite los pasos i y ii $1000$ veces para estimar el error estándar para 
una muestra de tamaño $n$.

#### Muestreo Aleatorio Simple
```{r}
# Definimos la semilla
set.seed(4556788)
# Definimos el vector n que contiene los tamaños de muestra
n   <- c(50,100,200,300,400,500,600,700)
# Juntamos los partidos en una sola variable recordando los principios
# de los datos limpios
y_i <- gto_2012 %>% gather(key="partido", value = "votos",
                           pri_pvem, pan_na, prd, pt, mc, otros) %>% 
  group_by(partido) %>%  
  # Agregamos la variable de proporción de votos para cada partido 
  summarise("prop" = sum(votos)/sum(total))

# Nos quedamos únicamente con las proporciones por partido para 
# poder realizar el muestreo aleatorio simple
p_i <- y_i %>%select("prop") %>% unlist()

# Definimos una función para las simulaciones
sim_p_hat <- function(n, p, n_sims = 1000){
  # Simulamos de una multinomial con n el tamaño de
  # muestra y p las proporciones de votos para
  # partido
  sim_muestra <- rmultinom(n_sims, n, p)
  # Obtenemos el estimador de razón para este
  # tipo de muestreo
  p_razon     <- sim_muestra/n
  # Obtenemos el error estándar para cada candidato
  SE_cand     <- c()
  for(i in 1:nrow(sim_muestra)){
    SE_cand <- c(SE_cand, sd(p_razon[i,])/sqrt(n))
  }
  return(SE_cand)
}

# Simulamos los errores estándar dadas las proporciones
# observadas
SE <- sim_p_hat(n[1], p_i)

# Juntamos los errores estándar para los distintos tamaños de muestra
for (j in 2:length(n)) {
  SE <- cbind(SE, sim_p_hat(n[j], p_i))
}

# Le damos formato para generar una tabla con los SE
colnames(SE) <- as.character(n)
SE <- formatC(SE, digits = 4, format = "f")
SE

# Le damos formato para generar una tabla con la longitud de los ICs
IClength <- 1.96*SE
IClength <- formatC(IClength, digits = 4, format = "f")
IClength
```

Para muestro aleatorio simple y dado el estimador de razón para cada candidato $\hat{p}_i$ se tiene que el tamaño de muestra tal que la longitud del intervalo de confianza sea menor a dos puntos porcentuales es al menos 400.


Para cada posible **estratificación** (`distrito_fed_17` y `distrito_loc_17`) y 
tamaño de muestra $n=50,100,200,300,400,500,600,700$:

i. Simula una muestra estratificada de tamaño $n$, donde el tamaño de muestra en 
cada estrato se asigna proporcional al tamaño del estrato, esto es, sea $N_h$ el 
número de casillas en el $h$-ésimo estrato, entonces para el estrato $h$ el 
número de casillas en la muestra será:
$$n_h = N_h \cdot \frac{n}{\sum_j N_j}$$
ii. Calcula el estimador de razón combinado (correspondiente a muestreo 
estratificado) para cada candidato:

$$\hat{p}=\frac{\sum_h \frac{N_h}{n_h} \sum_i Y_{hi}}{\sum_h \frac{N_h}{n_h} \sum_i X_{hi}}$$
donde:

* $\hat{p}$ es la estimación de la proporción de votos que recibió el candidato
en la elección.

* $Y_{hi}$ es el número total de votos que recibió el candidato
en la $i$-ésima casillas, que pertence al $h$-ésimo estrato.

* $X_{hi}$ es el número total de votos en la $i$-ésima casilla, que pertence al 
$h$-ésimo estrato. 

* $N_h$ es el número total de casillas en el $h$-ésimo estrato.

* $n_h$ es el número de casillas del $h$-ésimo estrato que se seleccionaron en 
la muestra.

iii. Repite los pasos i y ii $1000$ veces para estimar el error estándar para 
una muestra de tamaño $n$.

#### Muestreo estratificado

```{r}
# Nuevamente seguimos los principios de los datos limpios 
# para definir una única variable con el partido
# Creamos dos variables "estrato_local" y "estrato_federal"
# para poder tener un mejor manejo de la base.

base2 <- gto_2012 %>%  gather(key="partido", value = "votos",
                              pri_pvem, pan_na, prd, pt, mc, otros) %>% 
  mutate("estrato_local" = distrito_loc_17) %>% 
  mutate("estrato_federal" = distrito_fed_17)


```

##### Muestreo estratificado por distrito local

```{r}
# Creamos una función que hace un muestreo de las casillas por estrato
Muestrasim <- function(base,i, nh){
  Muestra <- base %>% filter(estrato_local==estrato_local[i])
  sample_n( Muestra, nh[i],replace = TRUE)
}

```


```{r}
# Creamos una función que calcula el estimador de razon para el estrato local
# y tamaño de muestra n
propRazon <- function(n, base){
  
  # Se cuentan las casillas por estrato y se dividen entre 
  # el tamaño de muestra, tomamos el techo, ya que no se pueden
  # tomar fracciones de las casillas
  Nh0 <- base %>%  group_by(estrato_local) %>% 
    summarise(Nh=n()) %>% 
    mutate("nh" = ceiling(Nh*n/sum(Nh)))
  
  nh <- unlist(Nh0$nh)
  
  # Muestreamos las casillas que utilizaremos
  baseMuestra  <- Muestrasim(base,1,nh)
  
  # Se repite para todos los estratos
  for(i in 2:nrow(Nh0)){
    baseMuestra <- rbind(baseMuestra, Muestrasim(base,i,nh))
  }
  
  # Obtenemos el numerador del estimador de razón
  Nh <- baseMuestra %>%  group_by(estrato_local) %>% 
    summarise(Nh=n()) %>% 
    mutate("nh" = ceiling(Nh*n/sum(Nh)))
  
  numerador <- baseMuestra %>% group_by(estrato_local, partido) %>% 
    summarise(Votos_estrato = sum(votos)) %>% 
    left_join(Nh,"estrato_local") %>% 
    group_by(partido) %>% 
    summarise(numerador = sum(Votos_estrato*Nh/nh))
  
  # Obtenemos el denominador del estimador de razón
  denominador <- baseMuestra %>% group_by(estrato_local) %>% 
    summarise(votos_Estrato=sum(votos)) %>% 
    left_join(Nh, "estrato_local") %>% 
    ungroup() %>% 
    summarise(denom=sum(votos_Estrato*Nh/nh))
  # Calculamos el estimador de razón
  prop <- numerador$numerador/denominador$denom
  return(prop)
}


```

```{r}
# Simulamos el error estándar para el estrato local
Sim_cand_estrato_Loc <- function(i){
  # Generamos 1000 simulaciones del estimador de razón para el tamaño de muestra i
  Propsim <- rerun(1000, propRazon(i, base2)) %>% unlist() %>% 
    matrix(ncol = 1000, byrow = FALSE)
  
  # Para cada candidato obtenemos el error estándar en el
  # estrato local
  
  SE_cand     <- c()
  
  for(j in 1:nrow(Propsim)){
    SE_cand <- c(SE_cand, sd(Propsim[j,])/sqrt(i))
  }
  return(SE_cand)
}
```

```{r}
# Hacemos las simulaciones para cada estrato
SE_cand_estrato_Loc <- Sim_cand_estrato_Loc(n[1])

for (j in 2:length(n)) {
  SE_cand_estrato_Loc  <- cbind(SE_cand_estrato_Loc, Sim_cand_estrato_Loc(n[j]))
}

# Se le da formato a la tabla de error estándar por estrato local
colnames(SE_cand_estrato_Loc) <- as.character(n)
SE_cand_estrato_Loc <- formatC(SE_cand_estrato_Loc, digits = 4, format = "f")
SE_cand_estrato_Loc

# Se le da formato a la tabla de tamaño del IC por estrato local
IClength_estrato_Loc <- 1.96*SE_cand_estrato_Loc
IClength_estrato_Loc <- formatC(IClength_estrato_Loc, digits = 4, format = "f")
IClength_estrato_Loc
```

##### Muestreo estratificado por distrito federal

```{r}
# Creamos un código para muestrear casillas del estrato federal
MuestrasimFed <- function(base,i, nh){
  Muestra <- base %>% filter(estrato_federal==estrato_federal[i])
  sample_n( Muestra, nh[i],replace = TRUE)
}

```


```{r}
# Creamos una función para calcular el estimador de razón
# para el estrato federal y tamaño de muestra n
propRazonFed <- function(n, base){
  # Se cuentan las casillas por estrato y se dividen entre 
  # el tamaño de muestra, tomamos el techo, ya que no se pueden
  # tomar fracciones de las casillas
  Nh0 <- base %>%  group_by(estrato_federal) %>% 
    summarise(Nh=n()) %>% 
    mutate("nh" = ceiling(Nh*n/sum(Nh)))
  
  nh <- unlist(Nh0$nh)
  
  # Muestreamos las casillas que utilizaremos
  baseMuestra  <- MuestrasimFed(base,1,nh)
  
  # Se repite para todos los estratos
  for(i in 2:nrow(Nh0)){
    baseMuestra <- rbind(baseMuestra, MuestrasimFed(base,i,nh))
  }
  
  # Obtenemos el numerador del estimador de razón
  Nh <- baseMuestra %>%  group_by(estrato_federal) %>% 
    summarise(Nh=n()) %>% 
    mutate("nh" = ceiling(Nh*n/sum(Nh)))
  
  numerador <- baseMuestra %>% group_by(estrato_federal, partido) %>% 
    summarise(Votos_estrato = sum(votos)) %>% 
    left_join(Nh,"estrato_federal") %>% 
    group_by(partido) %>% 
    summarise(numerador = sum(Votos_estrato*Nh/nh))
  
  # Obtenemos el denominador para el estimador de razón
  denominador <- baseMuestra %>% group_by(estrato_federal) %>% 
    summarise(votos_Estrato=sum(votos)) %>% 
    left_join(Nh, "estrato_federal") %>% 
    ungroup() %>% 
    summarise(denom=sum(votos_Estrato*Nh/nh))
  
  # Calculamos el estimador de razón
  prop <- numerador$numerador/denominador$denom
  return(prop)
}


```

```{r}
# Simulamos el error estándar para el estrato federal
Sim_cand_estrato_Federal <- function(i){
  # Generamos 1000 simulaciones del estimador de razón para el tamaño de muestra i
  Propsim <- rerun(1000, propRazonFed(i, base2)) %>% unlist() %>% 
    matrix(ncol = 1000, byrow = FALSE)
  
  SE_cand     <- c()
  
  # Para cada candidato obtenemos el error estándar en el
  # estrato local
  for(j in 1:nrow(Propsim)){
    SE_cand <- c(SE_cand, sd(Propsim[j,])/sqrt(i))
  }
  return(SE_cand)
}

```

```{r}
# Hacemos las simulaciones para cada estrato
SE_cand_estrato_Fed <- Sim_cand_estrato_Federal(n[1])

for (j in 2:length(n)) {
  SE_cand_estrato_Fed  <- cbind(SE_cand_estrato_Fed, Sim_cand_estrato_Federal(n[j]))
}
# Se le da formato a la tabla de error estándar por estrato federal
colnames(SE_cand_estrato_Fed) <- as.character(n)
SE_cand_estrato_Fed <- formatC(SE_cand_estrato_Fed, digits = 4, format = "f")
SE_cand_estrato_Fed
# Se le da formato a la tabla de longitud del IC por estrato federal
IClength_estrato_Fed <- 1.96*SE_cand_estrato_Fed
IClength_estrato_Fed <- formatC(IClength_estrato_Fed, digits = 4, format = "f")
IClength_estrato_Fed
```


Ahora:

1. Reporta en una tabla el error estándar para cada candidato, tamaño de muestra
y diseño (MAS/estratificaciones).

```{r}
# Juntamos las distintas tablas en una tabla con toda la información
tablaTodos <- data.frame(rbind(cbind("Diseño"=rep("MAS",6), "Candidato"=cbind(y_i$partido), SE),
                               cbind("Diseño"=rep("Local",6), "Candidato"=cbind(y_i$partido), SE_cand_estrato_Loc),
                               cbind("Diseño"=rep("Federal",6), "Candidato"=cbind(y_i$partido), SE_cand_estrato_Fed)), stringsAsFactors = FALSE)
names(tablaTodos) <- c("Diseño", "Candidato", paste0("TamMuestra_", n))
tablaTodos
```


2. Grafica los datos de la tabla: realiza una gráfica de paneles (con 
`facet_wrap()`), cada partido en un panel, en el eje horizontal grafica el 
tamaño de muestra y en el eje vertical el error estándar, tendrás en una misma 
gráfica tres curvas, una para muestreo aleatorio simple y una para 
cada estratificación.

```{r}
# Graficamos el error estándar por partido, muestreo y tamaño de muestra

tablaTodos[,3:ncol(tablaTodos)]<- matrix(unlist(lapply(3:ncol(tablaTodos), function(i){as.numeric(tablaTodos[,i])})), 
                                         nrow = nrow(tablaTodos), byrow = TRUE)

tablaTodosgraf <- tablaTodos %>% gather("Tamaño", "SE" ,TamMuestra_50:TamMuestra_700) %>% 
  mutate("Tamaño"=as.numeric(substr(Tamaño, 12,14)))

ggplot(tablaTodosgraf)+theme_bw()+
  geom_line(aes(Tamaño, SE, col=Diseño))+
  facet_wrap(~Candidato)
```


3. ¿Qué diseño y tamaño de muestra elegirías? Explica tu respuesta y de 
ser necesario repite los pasos i-iii para otros valores de $n$.

HAY QUE HACERLO DESPUÉS DE CORRERLO!!!!!

### 3. MCMC {-}

Siguiendo con el conteo rápido de Guanajuato, calcularás intervalos de confianza
usando el modelo propuesto en @mendoza2016.

Los autores proponen ajustar un modelo de manera independiente para cada 
candidato en cada estrato:

```{r, echo=FALSE, eval=TRUE}
source("QuickCountSampleProp.R")
muestra_gto <- select_sample_prop(gto_2012, stratum = distrito_fed_17, 
                                  frac = 0.06, seed = 821023)
write_csv(muestra_gto, "data/muestra_gto_2012_2.csv")
```

* Verosimilitud

$$X_{ij}^k\big|\theta_{ij},\tau_{ij}\sim N\bigg(n_i^k\theta_{ij}, \frac{\tau_{ij}}{n_i^k}\bigg)$$

para $k=1,...,c_i$, $i = 1,...,N$, $j=1,...,J$

* Iniciales

$$p(\theta_{i,j},\tau_{ij})\propto \tau_{ij}^{-1}I(\tau_{ij}>0)I(0<\theta_{i,j}<1)$$

* Posterior

$$p(\theta_{ij}, \tau_{ij}|X_{ij}) \sim N\bigg(\theta_{ij} \bigg| \frac{\sum_{k=1}^{c_i}x_{ij}^k}{\sum_{k=1}^{c_i}n_{i}^k}, \tau_{ij}\sum_{k=1}^{c_i}n_i^k\bigg)I(0<\theta_{ij}<1)\times Ga\bigg(\tau_{ij}\bigg|\frac{c_i-1}{2}, \frac{1}{2}\bigg[\sum_{k=1}^{c_i}\frac{(x_{ij}^k)^2}{n_i^k}-\frac{\big(\sum_{k=1}^{c_i}x_{ij}^k\big)^2}{\sum_{k=1}^{c_i}n_i^k}\bigg]\bigg)$$
donde:

* $X_{ij}$ número de personas que favorecen al candidato $j$ en el estrato $i$.

* $X_{ij}^k$ número de personas que favorecen al candidato $j$ en la casilla $k$ 
del estrato $i$.

* $n_i^k$ tamaño de la lista nominal en la $k$-ésima casilla del $i$-ésimo 
estrato.

* $\tau_{ij}/n_i^{k}$ es la precisión para cada candidato.

* $\theta_{ij}$ es la proporción de las personas en la lista nominal del estrato
$i$ que favorecen al $j$-ésimo partido.

* $c_i$ número de casillas del $i$-ésimo estrato en la muestra.

Los detalles del modelo los puedes encontrar en el [artículo](https://drive.google.com/open?id=1lI5lUSqNcIYvlvxRyrbBD_IrzlWIzILY).

Implementa el modelo y estima los resultados electorales de Guanajuato con la 
muestra:

```{r, message=FALSE}
gto_muestra <- read.csv("data/muestra_gto_2012_2.csv", stringsAsFactors = FALSE)

# Eliminamos el estrato con una sola casilla para evitar que la posterior sea impropia
gto_muestra  <- gto_muestra %>% filter(distrito_fed_17!=20)
```

```{r}
# Obtener nik
nik <- gto_muestra %>% group_by(casilla_id, distrito_fed_17) %>% 
  summarise("nik"=sum(ln_total))
nik <- nik %>% ungroup() %>% 
  mutate("casilla_id"=as.numeric(as.factor(casilla_id))) %>% 
  mutate("distrito_fed_17"=as.numeric(as.factor(distrito_fed_17)))

nik <- nik %>% spread(key =casilla_id, value = nik, fill = 0) %>%  select(-"distrito_fed_17") %>% as.matrix()
```


```{r}
gto_muestraVotos <- gto_muestra %>%  gather(key="partido", value = "votos",
                                            pri_pvem, pan_na, prd, pt, mc, otros)
# Número de estratos
Ni <- length(unique(gto_muestra$distrito_fed_17))

# Número de candidatos
Nj <- length(unique(gto_muestraVotos$partido))

# Número de casillas
Nk <- length(unique(gto_muestraVotos$casilla_id))

# Número de casillas por estrato
ci <- gto_muestra %>% group_by(distrito_fed_17) %>% summarise("ci"=n()) %>% 
  select("ci") %>% unlist()
```

```{r}
# Datos observados
Xijk <-  gto_muestraVotos %>% group_by(partido, distrito_fed_17, casilla_id) %>% 
  summarise("Xijk"=sum(votos)) %>% 
  ungroup() %>% 
  mutate("partido"=as.numeric(as.factor(partido))) %>% 
  mutate("casilla_id"=as.numeric(as.factor(casilla_id))) %>% 
  mutate("distrito_fed_17"=as.numeric(as.factor(distrito_fed_17)))


num_votos_estrato <- gto_muestraVotos %>% group_by(distrito_fed_17) %>% 
  summarise(total= sum(total)) %>% ungroup() %>% 
  select(-"distrito_fed_17") %>% as.matrix()




```


```{r}
# Posterior 
# Theta[1]: thetaij
# Theta[2]: tauij
postRelProb <- function(i,j, nik, Xijk){
  function(Theta){
    thetaij <- Theta[1]
    tauij   <- Theta[2]
    if(thetaij >0 & thetaij<1){
      # Vector de Xs para estrato i y candidato j
      Xs   <- Xijk %>% filter(distrito_fed_17==i & partido==j) %>% select("Xijk") %>%  unlist()
      
      # Vector de tamaño de la lista nominal en la casilla k
      ns   <- nik[i,]
      ns   <- ns[which(ns>0)]
      ci   <- length(ns)
      # Precalcular sumas de la distribución
      sum1 <- sum(Xs)/sum(ns)
      sum2 <- sum(ns)
      sum3 <- sum(Xs^2/ns)
      sum4 <- sum(Xs)^2/sum(ns)
      
      # Calcular probabilidad de thetaij
      p_thetaij <- dnorm(thetaij, sum1, 1/sqrt(tauij*sum2))
      # Calcular probabilidad de tauij
      p_tauij    <- dgamma(tauij, (ci-1)/2, 0.5*(sum3-sum4))
      # Calcular probabilidad conjunta de thetaij y tauij
      prob       <- p_thetaij * p_tauij
      return(prob)
    }
    else{
      return(0)
    }
  }
}
```



```{r}

# para cada paso decidimos el movimiento de acuerdo a la siguiente función
caminaAleat <- function(theta){ # theta: valor actual
  salto_prop <- MASS::mvrnorm(n = 1 , mu = rep(0, 2), 
                              Sigma = matrix(c(0.005, 0, 0, 0.005), byrow = TRUE, nrow = 2)) # salto propuesto
  theta_prop <- theta + salto_prop # theta propuesta
  if(theta_prop[1]< 0 | theta_prop[1] > 1 | theta_prop[2]<0){ # si el salto implica salir del dominio
    return(theta)
  }
  u <- runif(1) 
  p_move <-  min(postRelProb_ij(theta_prop) / postRelProb_ij(theta), 1) # prob mover
  if(p_move  > u){
    return(theta_prop) # aceptar valor propuesto
  }
  else{
    return(theta) # rechazar
  }
}
```



```{r}
set.seed(47405)
MCMC_ij <- function(i,j, theta0, pasos, calentamiento){
  postRelProb_ij <- postRelProb(i, j, nik, Xijk)
  camino         <- array(dim=c(pasos,2)) # vector que guardará las simulaciones
  camino[1,]     <- theta0 # valor inicial
  
  # Generamos la caminata aleatoria
  for (j in 2:pasos){
    camino[j,] <- caminaAleat(camino[j - 1,])
  }
  
  caminata <- data.frame(pasos = 1:(pasos-calentamiento), theta = camino[(calentamiento+1):pasos,])
  return(caminata)
}

```

```{r}
Npasos         <- 12500
Ncalentamiento <- 2500
for (i in 1:Ni) {
  for (j in 1:Nj) {
    theta0
    MCMC_ij(i,j, pasos = Npasos)
  }
}
```




Reporta estimaciones puntuales (media posterior) e intervalos del 95% de 
credibilidad para cada candidato

### 4. Modelos jerárquicos y evaluación de ajuste {-}

**Postestratificación** es un método estándar que se utiliza para corregir las 
estimaciones obtenidas de muestreo probabilístico cuando hay distintas 
probabilidades de selección y para corregir no respuesta. A grandes rasgos, se 
divide la población en categorías y se estima la distribución de las respuestas 
en cada categoría, después se pondera cada categoría de acuerdo a su tamaño en 
la población. Típicamente las categorías se crean con variables demográficas
(sexo, edad, ...). 

La dificultad que suele surgir en el proceso de postestratificación es que 
por una parte se desea crear las celdas lo más finas posible, considerando
el cruce de muchas variables, con el objetivo de corregir en mayor medida
posibles sesgos en las estimaciones; sin embargo, conforme aumenta el número de
celdas el número de respondentes en cada una disminuye (muchas incluso quedan
vacías) y esto conlleva a que las estimaciones dentro de cada celda sean poco
precisas. Ante esta dificultad, la propuesta de MRP es modelar las respuestas 
condicional a las variables de postestratificación, cuando las categorías de la
postestratificación siguen de manera natural estructuras jerárquicas (como 
hogares en estados) se puede mejorar la eficiencia de la estimación ajustando
modelos multinivel. 

Es así que MRP es una extensión a los ajustes de postestratificación clásicos 
que permite usar más categorías y por tanto información más detallada de la 
población. Una ventaja adicional es que además hace posible estimar la respuesta 
en subcategorias demográficas o geográficas. En este ejercicio reproduciremos 
el modelo que se ajusta en @parkgelmanbafumi lo puedes descargar de [esta liga ](http://www.stat.columbia.edu/~gelman/research/published/parkgelmanbafumi.pdf).

En esta aplicación se utilizan encuestas de opinión pública en EUA, en 
particular modelamos la probabilidad de que un respondente prefiera al 
candidato Republicano como presidente y usando los datos de encuestas de 
*CBS News* levantadas previo a la elección presidencial de 1988. 

Las variables demográficas que determinan las celdas de postestratificación son:
sexo, raza negra, edad (categórica), grado educativo y estado, si construyéramos 
las celdas de postestratificación quedarían, 

sexo(2) x raza negra(2) x edad(4) x educación(4) x estado(52) = 3264

celdas y tenemos únicamente 2193 entrevistas, por lo que un enfoque clásico 
utilizando todas las variables demográficas disponibles queda descartado.

Ahora, definimos el modelo multinivel a usar, usaremos regresión logística 
multinivel, en este planteamiento la variable $y_i$ indica si la
$i$-ésima persona apoyaba al candidato republicano o no, y se agregan todas las
variables demográficas como covariables.

$$
\begin{aligned}
P(y_i = 1) &= logit^{-1}(\beta^0 + \beta^{mujer}\cdot mujer_i + \beta^{neg}\cdot neg_i+\beta^{mujer, neg}\cdot mujer_i \cdot neg_i+ \\
& \beta_{edad(i)}^{edad} +  \beta_{edad(i), edu(i)}^{edad,edu} + 
\beta_{estado(i)}^{estado})
\end{aligned}
$$

En este ejemplo la estructura multinivel se reduce al coeficiente de
estado que se modela con indicadoras de región y una medida del apoyo
Republicano en el estado reportado en la elección previa.

$$ \beta_{j}\sim N(\beta_{region(j)}^{region}+\beta^{vprev}\cdot vprev_j, \sigma^2_{estado})$$

Ajustaremos este modelo usando el programa JAGS (Just Another Gibbs Sampler), y 
utilizamos las estimaciones para hacer predicciones a nivel estado ($\theta_s$):

$$\theta_s=\frac{\sum_{j \in s}N_{j}\pi_j}{\sum_{j \in s}N_{j}}$$

donde $N_j$ indica el número de individuos en cada estado que 
pertenecen a la $j$-ésima celda, la información para determinar las $N_j$ se 
obtendrá del censo de población.

### Implementación

Datos en [election88](http://www.stat.columbia.edu/~gelman/arm/examples/election88/), 
o en la carpeta data.

```{r}
# preparación de los datos
library(haven)
library(R2jags)
# datos de encuestas
polls <- read_dta("data/polls.dta")
# nos quedamos con la última encuesta y eliminamos faltantes
last_poll <- polls %>% 
  filter(survey == 8) %>% 
  na.omit()
# datos de elecciones pasadas para utilizar como covariable y variable región
presvote <- read_dta("data/presvote.dta") %>% 
  cbind(region = c(3,4,4,3,4,4,1,1,5,3,3,4,4,2,2,2,2,3,3,1,1,1,2,2,3,2,4,2,4,
                   1,1,4,1,3,2,2,3,4,1,1,3,2,3,3,4,1,3,4,1,2,4))
```

Los datos para el modelo serán:

```{r, eval=TRUE}
data_jags <- list(n = nrow(last_poll), 
                  n_region = 5, 
                  n_age = n_distinct(last_poll$age), 
                  n_edu = n_distinct(last_poll$edu), 
                  n_state = max(last_poll$state), 
                  y = last_poll$bush, 
                  female = last_poll$female,
                  edu = last_poll$edu,
                  age = last_poll$age,
                  black = last_poll$black,
                  state = last_poll$state, 
                  v_prev = presvote$g76_84pr,
                  region = presvote$region
)
```

Y el código en JAGS:

```{r, eval =TRUE}
model_mrp <- "
    model {
        for (i in 1:n){
            y[i] ~ dbern(p_bound[i])
            p_bound[i] <- max(0, p[i])
            p[i] <- ilogit(b_0 + b_female*female[i] + b_black * black[i] +
                b_female_black * female[i]*black[i] +
                a_age[age[i]] + a_edu[edu[i]] + a_age_edu[age[i],edu[i]] +
                a_state[state[i]])
    }
    b_0 ~ dnorm (0, .0001)
    b_female ~ dnorm (0, .0001)
    b_black ~ dnorm (0, .0001)
    b_female_black ~ dnorm (0, .0001)
    for (j in 1:n_age) {
        a_age[j] ~ dnorm(0, tau_age)}
    for (j in 1:n_edu) {
        a_edu[j] ~ dnorm(0, tau_edu)}
    for (j in 1:n_age) {
        for (k in 1:n_edu){
            a_age_edu[j,k] ~ dnorm(0, tau_age_edu)
        }
    }
    for (j in 1:n_state) {
        a_state[j] ~ dnorm(a_state_hat[j], tau_state)
        a_state_hat[j] <- a_region[region[j]] + b_v_prev*v_prev[j]
    }
    b_v_prev ~ dnorm (0, .0001) 
    for (j in 1:n_region) {
        a_region[j] ~ dnorm(0, tau_region)
    }
    tau_age <- pow(sigma_age, -2)
    tau_edu <- pow(sigma_edu, -2)
    tau_age_edu <- pow(sigma_age_edu, -2)
    tau_state <- pow(sigma_state, -2)
    tau_region <- pow(sigma_region, -2)
    sigma_age ~ dunif (0, 100)
    sigma_edu ~ dunif (0, 100)
    sigma_age_edu ~ dunif (0, 100)
    sigma_state ~ dunif (0, 100)
    sigma_region ~ dunif (0, 100)
    }
    "
cat(model_mrp, file = 'model_mrp.bugs')
```

1. **Modelo**. Ajusta el modelo y revisa convergencia, describe 
cuantas cadenas, iteraciones y etapa de calentamiento elegiste, además 
escribe como determinaste convergencia.

```{r}
last_poll <- last_poll %>% mutate("fem_black"=last_poll$female*last_poll$black) %>% 
  select(-c("year", "survey", "org"))

```



```{r, eval=TRUE}
# Definimos la función para generar valores inciales
init_theta <- function(){
  # Creamos una muestra aleatoria con reemplazo. 
  muestra <- sample(1:2015, 2015, replace = TRUE)
  x_s     <- last_poll[muestra,]
  ageCat  <- unique(last_poll$age)[order(unique(last_poll$age))]
  eduCat  <- unique(last_poll$edu)[order(unique(last_poll$edu))]
  # Hacemos un modelo con regresión logística para darle un valor inicial 
  # a los coeficientes
  model   <- glm(bush~., data = x_s, family = binomial(link = "logit"))
  Coefs   <- model$coefficients
  # Los coeficientes con distintos estratos como age y edu, les asignamos =
  # el valor del coeficiente dividido entre el valor de la categorìa.
  # Para la variable de state repetimos el mismo coeficiente para cada estado.
  # Para la categoría age_edu obtuvimos una matriz multiplicando el vector
  # de coeficientes asignados para edad contra el transpuesto de los asignados
  # para educación.
  # Para la inical de las varianzas ocupamos una uniforme que toma valores entre 0 y 100.
  
 list(b_0=Coefs[1], b_female =Coefs[5], b_black=Coefs[6],
       b_female_black=Coefs[8], a_age = Coefs[4]/ageCat,#
       a_edu = Coefs[3]/eduCat,
       a_age_edu=Coefs[4]/ageCat%*%t(Coefs[3]/eduCat),
       a_state=rep(Coefs[2],51), 
       sigma_age=runif(1,0,100), sigma_edu =runif(1,0,100),  
       sigma_age_edu=runif(1,0,100), sigma_state=runif(1,0,100),  
       sigma_region =runif(1,0,100))
}
```


```{r, eval=TRUE}
set.seed(12454)
jags_fit <- jags(
  model.file = "model_mrp.bugs",    # modelo de JAGS
  inits = init_theta,   # valores iniciales
  data = data_jags,    # lista con los datos
  parameters.to.save = c("b_0", "b_female", "b_black", "b_female_black",
                         "a_age", "a_edu", "a_age_edu", "a_state",
                         "sigma_age", "sigma_edu", "sigma_age_edu",
                         "sigma_state", "sigma_region"),  # parámetros por guardar
  n.chains = 4,   # número de cadenas
  n.iter = 5000,    # número de pasos
  n.burnin = 1000,   # calentamiento de la cadena
  n.thin = 4 
)
```



```{r}
plot(jags_fit)
```




2. **Evaluación de ajuste**. Usaremos la distribución predictiva posterior para
simular del modelo y comparar con los datos observados. En particular veremos 
como se comparan las simulaciones del modelo por estado, la gráfica con lo$s 
datos será la que sigue:

```{r, eval=FALSE}
bush_state <- last_poll %>% 
  group_by(state) %>% 
  summarise(prop = mean(bush, na.rm = TRUE)) %>% 
  ungroup() %>% 
  mutate(state_ord = as.numeric(reorder(state, prop)))
ggplot(bush_state, aes(x = state_ord, y = prop)) +
  geom_line()
```

Debes simular del modelo 10 conjutos de datos del tamaño de los originales 
(replicaciones de los datos) y hacer una gráfica de páneles donde muestres los 
datos originales y las replicaciones, ¿que concluyes al ver la gráfica?

```{r}
# Obtener las simulaciones de las variables del modelo
Vars <- c("b_0", "b_female", "b_black", "b_female_black",
          "a_age", "a_edu", "a_age_edu", "a_state")

for (i  in Vars) {
  assign(i, jags_fit$BUGSoutput$mean[[i]])
}

```

```{r}
# Replicaciones de los datos
for (i in 1:10) {
  muestra <- sample(1:2015, 2015, replace = TRUE)
  muestra <- last_poll[muestra,]
  assign(paste0("muestra_",i),muestra)
}
```

```{r, message=FALSE, warning=FALSE}
# Evaluación del modelo
Nsims    <- length(b_0)
invLogit <- function(x){exp(x)/(1+exp(x))}

for (i in 1:10) {
  muestra <- get(paste0("muestra_",i))
  nparam  <- sample(1:Nsims,1)
  muestra <- muestra %>% mutate("bush_pred"= b_0+ b_female*female +
                                  b_black * black +
                                  b_female_black * female*black +
                                  a_age[age] + a_edu[edu] +
                                  a_state[state])
  aux <- c()
  for (j in 1:2015) {
    aux <- c(aux,
             rbinom(1,1, invLogit(muestra$bush_pred[j] + 
                                    a_age_edu[muestra$age[j] , muestra$edu[j]])))
  }
  muestra$bush_pred <- aux
  assign(paste0("muestra_",i), muestra)
  bush_state_i  <- muestra %>% group_by(state) %>% 
    summarise(prop = mean(bush_pred, na.rm = TRUE)) %>% 
    ungroup() %>% 
    mutate(state_ord = as.numeric(reorder(state, prop))) %>% 
    mutate("sim"=i)
  assign(paste0("bush_state_",i), bush_state_i)
}

```

```{r}
bush_state_sims <- rbind(cbind(bush_state, "sim"=0),
                         bush_state_1, bush_state_2, bush_state_3,
                         bush_state_4, bush_state_5, bush_state_6,
                         bush_state_7, bush_state_8, bush_state_9,
                         bush_state_10)

ggplot(bush_state_sims, aes(x = state_ord, y = prop)) +
  geom_line()+
  facet_wrap(~ sim)+
  xlab("Estado")+ ylab("Proporció de votos por Bush")

```
 
 En general todas las gráficas son parecidas, en la quinta simulación hubo un poco más de error, pero se ve bien en la mayoría de los casos ya que se obtiene una gráfica similar a la original.

3. El siguiente código predice para cada celda de la tabla del censo, vale la 
pena notar, que para cada celda tenemos una lista en el vector `pred` con las 
simuaciones que le corresponden.

```{r}
# construct the n.sims x 3264 matrix
census88 <- read_dta("data/census88.dta")
glimpse(census88)
coef_sims <- jags_fit$BUGSoutput$sims.matrix
pred_cell <- census88 %>% 
  rowwise() %>% 
  mutate(
    pred = list(invLogit(coef_sims[, "b_0"] + 
                           coef_sims[, "b_female"] * female +
                           coef_sims[, "b_black"] * black + 
                           coef_sims[, "b_female_black"] * female * black +
                           coef_sims[, str_c("a_age[", round(age), "]")] +
                           coef_sims[, str_c("a_edu[", round(edu), "]")] +  
                           coef_sims[, str_c("a_age_edu[", round(age), ",", round(edu), "]")] +  
                           coef_sims[, str_c("a_state[", round(state), "]")]))) 
```


Para hacer las estimaciones por estado hace falta ponderar por el número de 
casos en cada celda:

$$\theta_s=\frac{\sum_{j \in s}N_{j}\pi_j}{\sum_{j \in s}N_{j}}$$
```{r}
# La función Expand la obtuvimos de:
# https://stackoverflow.com/questions/15930880/unlist-all-list-elements-in-a-dataframe
# y sirve para convertir los elementos de la lista en observaciones de la base
# para cada variable que contiene listas
Expand <- function(data) {
  ListCols <- sapply(data, is.list)
  cbind(data[!ListCols], t(apply(data[ListCols], 1, unlist)))
}
# Obtenemos la predicción por estado para cada simulación considerando
# la ponderación correspondiente.
PredSims_state <- Expand(pred_cell) %>% 
  gather("sims", "preds", pred1:pred40000) %>%
  group_by(state, sims) %>%
  summarise("preds"=sum(N*preds)/sum(N))
```

4. Genera las simulaciones de $\theta_s$, recuerda que debarás calcular una
simulación de cada $\theta_s$ por cada simulación de $\pi__j$ obtenida con el 
código de arriba. Realiza una gráfica con intervalos de credibilidad del 95% 
para cada $theta_s$.

```{r}
# Obtenemos los valores de la media y de los cuantiles 0.025 y 0.975
# para generar intervalos de confianza al $95%$
CI_Sims_state <- PredSims_state %>%  ungroup() %>% 
  group_by(state) %>% 
  summarise("mean"=mean(preds), "LB"=quantile(preds,0.025), "UB"=quantile(preds, 0.975))

glimpse(CI_Sims_state)
```

```{r}
# Graficamos los intervalos de confianza
ggplot(CI_Sims_state)+theme_bw()+
  geom_point(aes(state, mean), col="black")+
  geom_pointrange(aes(state, y=mean, ymin = LB, ymax = UB), size = 0.25)+
  xlab("Estado")+ylab("Probabilidad de triunfo de Bush")
```

